{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Whats going on in the model\n",
        "\n",
        "\n",
        "**Input and Output**\n",
        "\n",
        "**Input:** The input to the model is padded sequences of integer-encoded words representing pairs of events extracted from the TML files (TimeBank and TimeEval-3 datasets). Each sequence corresponds to a pair of events with their associated text descriptions.\n",
        "\n",
        "**Output**: The output is a label indicating the temporal relation between the two events (e.g., \"BEFORE\", \"AFTER\", \"SIMULTANEOUS\"). The model outputs a probability distribution over these possible relations, from which the most probable relation is selected\n",
        "\n",
        "\n",
        "\n",
        "1.** Data Splitting**\n",
        "\n",
        "Purpose: To separate the combined and preprocessed data into training and testing sets.\n",
        "\n",
        "Process:\n",
        "\n",
        "X_train, X_test, y_train, y_test: These variables hold the training and testing data for both input sequences (X) and labels (y).\n",
        "The train_test_split function is used to randomly split the data, with 80% going to training and 20% to testing.\n",
        "Outcome: The data is divided into X_train, y_train for training and X_test, y_test for testing.\n",
        "\n",
        "**2. Model Building**\n",
        "\n",
        "**Purpose:** To create an LSTM (Long Short-Term Memory) neural network model for sequence prediction.\n",
        "\n",
        "Architecture:\n",
        "\n",
        "**Embedding Layer:** Converts integer-encoded words (from the tokenizer) into dense vectors of fixed size (128). This layer allows the model to learn the relationship between words.\n",
        "\n",
        "LSTM Layer: This layer processes the sequences and captures the temporal dependencies between words. It outputs a fixed-size vector that represents the sequence.\n",
        "\n",
        "Dropout Layer: This layer is used to prevent overfitting by randomly setting a fraction of the input units to 0 at each update during training.\n",
        "\n",
        "Dense Layer: A fully connected layer that processes the output of the LSTM layer.\n",
        "\n",
        "Output Layer: A dense layer with a softmax activation function, which outputs a probability distribution over all possible label classes.\n",
        "\n",
        "**3. Model Training**\n",
        "\n",
        "Purpose: To fit the model to the training data, allowing it to learn patterns in the sequences.\n",
        "\n",
        "Process:\n",
        "\n",
        "The model is trained using the fit method, where it processes the training data in batches of 32 sequences at a time.\n",
        "The model runs for 10 epochs, meaning it goes through the entire training set 10 times.\n",
        "Validation is performed on the test data after each epoch to monitor how well the model generalizes.\n",
        "\n",
        "Outcome: The model learns from the training data, and its performance is tracked over the epochs.\n",
        "\n"
      ],
      "metadata": {
        "id": "19MThQ6bsO1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1: Data Extraction and Sequence Creation"
      ],
      "metadata": {
        "id": "0jRiMtc1pAbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Function to extract events from a TML file\n",
        "def extract_events(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    events = []\n",
        "\n",
        "    for i, event in enumerate(root.findall('.//EVENT')):\n",
        "        event_text = event.text.strip() if event.text else \"\"\n",
        "        event_class = event.get('class')\n",
        "        event_tense = event.get('tense')\n",
        "        event_aspect = event.get('aspect')\n",
        "        events.append({\n",
        "            'event_id': i,\n",
        "            'text': event_text,\n",
        "            'class': event_class,\n",
        "            'tense': event_tense,\n",
        "            'aspect': event_aspect\n",
        "        })\n",
        "\n",
        "    return events\n",
        "\n",
        "# Function to extract temporal relations from a TML file\n",
        "def extract_temporal_relations(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    relations = []\n",
        "\n",
        "    for tlink in root.findall('.//TLINK'):\n",
        "        event_1 = tlink.get('eventInstanceID')\n",
        "        event_2 = tlink.get('relatedToEventInstance')\n",
        "        relation_type = tlink.get('relType')\n",
        "        relations.append({\n",
        "            'event_1': event_1,\n",
        "            'event_2': event_2,\n",
        "            'relation': relation_type\n",
        "        })\n",
        "\n",
        "    return relations\n",
        "\n",
        "# Extract data from TimeBank\n",
        "timebank_file_path = 'TimeBank.tml'  # Replace with actual file path\n",
        "timebank_events = extract_events(timebank_file_path)\n",
        "timebank_relations = extract_temporal_relations(timebank_file_path)\n",
        "\n",
        "# Convert to DataFrames\n",
        "timebank_events_df = pd.DataFrame(timebank_events)\n",
        "timebank_relations_df = pd.DataFrame(timebank_relations)\n",
        "\n",
        "# Display TimeBank DataFrames\n",
        "print(\"TimeBank Events DataFrame:\")\n",
        "print(timebank_events_df.head())  # Display first few rows\n",
        "print(\"\\nTimeBank Relations DataFrame:\")\n",
        "print(timebank_relations_df.head())\n",
        "\n",
        "# Create sequences and labels\n",
        "timebank_sequences, timebank_labels = create_sequences(timebank_events_df, timebank_relations_df)\n",
        "timebank_sequences_df = pd.DataFrame({'sequence': timebank_sequences, 'label': timebank_labels})\n",
        "\n",
        "# Display TimeBank Sequences DataFrame\n",
        "print(\"\\nTimeBank Sequences DataFrame:\")\n",
        "print(timebank_sequences_df.head())\n",
        "\n",
        "# Extract data from TimeEval-3\n",
        "timeeval_file_path = 'TimeEval3.tml'  # Replace with actual file path\n",
        "timeeval_events = extract_events(timeeval_file_path)\n",
        "timeeval_relations = extract_temporal_relations(timeeval_file_path)\n",
        "\n",
        "# Convert to DataFrames\n",
        "timeeval_events_df = pd.DataFrame(timeeval_events)\n",
        "timeeval_relations_df = pd.DataFrame(timeeval_relations)\n",
        "\n",
        "# Display TimeEval-3 DataFrames\n",
        "print(\"\\nTimeEval-3 Events DataFrame:\")\n",
        "print(timeeval_events_df.head())\n",
        "print(\"\\nTimeEval-3 Relations DataFrame:\")\n",
        "print(timeeval_relations_df.head())\n",
        "\n",
        "# Create sequences and labels\n",
        "timeeval_sequences, timeeval_labels = create_sequences(timeeval_events_df, timeeval_relations_df)\n",
        "timeeval_sequences_df = pd.DataFrame({'sequence': timeeval_sequences, 'label': timeeval_labels})\n",
        "\n",
        "# Display TimeEval-3 Sequences DataFrame\n",
        "print(\"\\nTimeEval-3 Sequences DataFrame:\")\n",
        "print(timeeval_sequences_df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjtpK6f5o9Nc",
        "outputId": "8ccfa8c8-4fb1-45a7-f33f-fbc69e9dd1cf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TimeBank Events DataFrame:\n",
            "   event_id      text       class tense aspect\n",
            "0         0  watching  OCCURRENCE  None   None\n",
            "1         1    killed  OCCURRENCE  None   None\n",
            "2         2   emptied  OCCURRENCE  None   None\n",
            "3         3      said   REPORTING  None   None\n",
            "4         4  appeared  OCCURRENCE  None   None\n",
            "\n",
            "TimeBank Relations DataFrame:\n",
            "  event_1 event_2     relation\n",
            "0   ei236    None       BEFORE\n",
            "1   ei224    None       BEFORE\n",
            "2   ei216   ei215     INCLUDES\n",
            "3   ei237    None  IS_INCLUDED\n",
            "4   ei239    None  IS_INCLUDED\n",
            "\n",
            "TimeBank Sequences DataFrame:\n",
            "Empty DataFrame\n",
            "Columns: [sequence, label]\n",
            "Index: []\n",
            "\n",
            "TimeEval-3 Events DataFrame:\n",
            "   event_id     text       class tense aspect\n",
            "0         0   dipped  OCCURRENCE  None   None\n",
            "1         1  falling  OCCURRENCE  None   None\n",
            "2         2   whammy  OCCURRENCE  None   None\n",
            "3         3  reeling  OCCURRENCE  None   None\n",
            "4         4     said   REPORTING  None   None\n",
            "\n",
            "TimeEval-3 Relations DataFrame:\n",
            "  event_1 event_2 relation\n",
            "0     ei1    None   BEFORE\n",
            "1     ei9    None   BEFORE\n",
            "2     ei6    None   BEFORE\n",
            "3    ei30    None   BEFORE\n",
            "4    ei22    None   BEFORE\n",
            "\n",
            "TimeEval-3 Sequences DataFrame:\n",
            "           sequence   label\n",
            "0      led declined  BEFORE\n",
            "1   limited lending   AFTER\n",
            "2  touching limited  BEFORE\n",
            "3   limited session   AFTER\n",
            "4    touching quell   AFTER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Combine TimeBank and TimeEval-3 DataFrames\n",
        "combined_sequences_df = pd.concat([timebank_sequences_df, timeeval_sequences_df], ignore_index=True)\n",
        "\n",
        "# Display Combined Sequences DataFrame\n",
        "print(\"\\nCombined Sequences DataFrame:\")\n",
        "print(combined_sequences_df.head())\n",
        "\n",
        "# Clean and preprocess sequences\n",
        "def clean_text(text):\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "combined_sequences_df['cleaned_sequence'] = combined_sequences_df['sequence'].apply(clean_text)\n",
        "\n",
        "# Display Cleaned Sequences\n",
        "print(\"\\nCombined Cleaned Sequences DataFrame:\")\n",
        "print(combined_sequences_df[['sequence', 'cleaned_sequence']].head())\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(combined_sequences_df['cleaned_sequence'])\n",
        "combined_sequences_encoded = tokenizer.texts_to_sequences(combined_sequences_df['cleaned_sequence'])\n",
        "\n",
        "# Padding\n",
        "max_length = max(len(seq) for seq in combined_sequences_encoded)\n",
        "combined_sequences_padded = pad_sequences(combined_sequences_encoded, maxlen=max_length, padding='post')\n",
        "\n",
        "# Display Encoded and Padded Sequences\n",
        "print(\"\\nSample Encoded Sequences:\")\n",
        "print(combined_sequences_encoded[:5])  # Display first 5 sequences\n",
        "\n",
        "print(\"\\nPadded Sequences:\")\n",
        "print(combined_sequences_padded[:5])  # Display first 5 padded sequences\n",
        "\n",
        "# Encode Labels\n",
        "label_encoder = LabelEncoder()\n",
        "combined_labels_encoded = label_encoder.fit_transform(combined_sequences_df['label'])\n",
        "\n",
        "# Display Encoded Labels\n",
        "print(\"\\nEncoded Labels:\")\n",
        "print(combined_labels_encoded[:5])  # Display first 5 encoded labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMmJgC0aqciY",
        "outputId": "81f4337d-751d-4a1a-aa2e-83eb5c9b3f5b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined Sequences DataFrame:\n",
            "           sequence   label\n",
            "0      led declined  BEFORE\n",
            "1   limited lending   AFTER\n",
            "2  touching limited  BEFORE\n",
            "3   limited session   AFTER\n",
            "4    touching quell   AFTER\n",
            "\n",
            "Combined Cleaned Sequences DataFrame:\n",
            "           sequence  cleaned_sequence\n",
            "0      led declined      led declined\n",
            "1   limited lending   limited lending\n",
            "2  touching limited  touching limited\n",
            "3   limited session   limited session\n",
            "4    touching quell    touching quell\n",
            "\n",
            "Sample Encoded Sequences:\n",
            "[[8, 3], [4, 9], [1, 4], [4, 10], [1, 11]]\n",
            "\n",
            "Padded Sequences:\n",
            "[[ 8  3]\n",
            " [ 4  9]\n",
            " [ 1  4]\n",
            " [ 4 10]\n",
            " [ 1 11]]\n",
            "\n",
            "Encoded Labels:\n",
            "[1 0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_sequences_padded, combined_labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shape of the training and testing data\n",
        "print(\"\\nTraining Data Shape:\", X_train.shape)\n",
        "print(\"Training Labels Shape:\", y_train.shape)\n",
        "print(\"Test Data Shape:\", X_test.shape)\n",
        "print(\"Test Labels Shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKcerMdVqwKT",
        "outputId": "2cee299e-f55f-41bd-9058-1e9a4cd10678"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Data Shape: (12, 2)\n",
            "Training Labels Shape: (12,)\n",
            "Test Data Shape: (4, 2)\n",
            "Test Labels Shape: (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_length))\n",
        "\n",
        "# LSTM layer\n",
        "model.add(LSTM(units=128, return_sequences=False))\n",
        "\n",
        "# Dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Dense layer\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "1m52n2V-q0Nz",
        "outputId": "3d7dd5b6-466f-48a7-862b-8586292e7072"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Display training history\n",
        "print(\"\\nTraining History:\")\n",
        "print(history.history)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBUl5VD8q2fu",
        "outputId": "d701b3b9-d0d3-4c1c-9ea8-de3e87895b09"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.3333 - loss: 1.1009 - val_accuracy: 0.5000 - val_loss: 1.0953\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5833 - loss: 1.0929 - val_accuracy: 0.5000 - val_loss: 1.0952\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.3333 - loss: 1.0965 - val_accuracy: 0.5000 - val_loss: 1.0945\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6667 - loss: 1.0879 - val_accuracy: 0.5000 - val_loss: 1.0934\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.5833 - loss: 1.0857 - val_accuracy: 0.5000 - val_loss: 1.0922\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.4167 - loss: 1.0831 - val_accuracy: 0.5000 - val_loss: 1.0911\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.6667 - loss: 1.0758 - val_accuracy: 0.5000 - val_loss: 1.0896\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5833 - loss: 1.0749 - val_accuracy: 0.5000 - val_loss: 1.0880\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7500 - loss: 1.0688 - val_accuracy: 0.5000 - val_loss: 1.0864\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.6667 - loss: 1.0622 - val_accuracy: 0.5000 - val_loss: 1.0846\n",
            "\n",
            "Training History:\n",
            "{'accuracy': [0.3333333432674408, 0.5833333134651184, 0.3333333432674408, 0.6666666865348816, 0.5833333134651184, 0.4166666567325592, 0.6666666865348816, 0.5833333134651184, 0.75, 0.6666666865348816], 'loss': [1.1009498834609985, 1.0929304361343384, 1.0965386629104614, 1.0878721475601196, 1.085670828819275, 1.0830549001693726, 1.0757988691329956, 1.0749081373214722, 1.0688220262527466, 1.0621721744537354], 'val_accuracy': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'val_loss': [1.0953315496444702, 1.095160722732544, 1.0944757461547852, 1.0933738946914673, 1.092234492301941, 1.0910992622375488, 1.0896233320236206, 1.0880132913589478, 1.0864394903182983, 1.0846385955810547]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Display the evaluation results\n",
        "print(\"\\nTest Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kZqJeqirQwn",
        "outputId": "da7885e1-2657-4424-c8bf-01a365c506bb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 1.0846\n",
            "\n",
            "Test Loss: 1.0846385955810547\n",
            "Test Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert predictions to label indices\n",
        "y_pred_labels = y_pred.argmax(axis=-1)\n",
        "\n",
        "# Display some predictions\n",
        "print(\"\\nSample Predictions:\")\n",
        "for i in range(5):  # Display the first 5 predictions\n",
        "    print(f\"Predicted: {label_encoder.inverse_transform([y_pred_labels[i]])[0]}, Actual: {label_encoder.inverse_transform([y_test[i]])[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "QPbrHIQwrVLj",
        "outputId": "2da570b1-76e7-4f66-810f-982192382715"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\n",
            "Sample Predictions:\n",
            "Predicted: AFTER, Actual: BEFORE\n",
            "Predicted: AFTER, Actual: AFTER\n",
            "Predicted: AFTER, Actual: AFTER\n",
            "Predicted: SIMULTANEOUS, Actual: BEFORE\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 4 is out of bounds for axis 0 with size 4",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-5c77ff34224f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSample Predictions:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Display the first 5 predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted: {label_encoder.inverse_transform([y_pred_labels[i]])[0]}, Actual: {label_encoder.inverse_transform([y_test[i]])[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
          ]
        }
      ]
    }
  ]
}