{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJc5oV6Iy-Fe"
      },
      "source": [
        "# Problem Formulation\n",
        "\n",
        "Instead of predicting whether one event occurs before another (binary classification), the goal is to predict the entire sequence of events in the correct chronological order. This shifts the focus from pairwise comparisons to sequence prediction.\n",
        "\n",
        "#Inputs and Outputs\n",
        "\n",
        "Inputs: A sequence of events, represented by their textual descriptions. Each event within a context (e.g., a sentence or paragraph) is tokenized and represented as a sequence of embeddings.\n",
        "\n",
        "Outputs: The output is a sequence representing the correct chronological order of these events. For example, if three events are given, the model might output a permutation of indices like [2, 0, 1], indicating the correct order.\n",
        "\n",
        "#The Architecture\n",
        "\n",
        "1. Input Representation\n",
        "The input to the model is a sequence of events, where each event is represented as a tokenized sequence of words.\n",
        "\n",
        "Event Sequence: Each event is turned into a sequence of tokens (e.g., words or subwords).\n",
        "Contextual Information: The context of each event (e.g., the surrounding sentence) is also tokenized and can be included to provide additional information.\n",
        "2. Embedding Layer\n",
        "\n",
        "The tokenized sequences are passed through an Embedding Layer. This layer converts each token (word) into a dense vector representation, capturing semantic meanings and relationships between words.\n",
        "The result is a sequence of embeddings representing the events and their contexts.\n",
        "\n",
        "3. Sequence Processing (LSTM/GRU)\n",
        "The embedded event sequences are fed into LSTM (Long Short-Term Memory) or GRU (Gated Recurrent Unit) layers.\n",
        "These layers process the sequence of embeddings, capturing temporal dependencies and the order in which events occur.\n",
        "Since LSTMs can remember long-term dependencies, they are well-suited for understanding the sequence and temporal relationships between events.\n",
        "\n",
        "4. Attention Mechanism (Optional)\n",
        "An Attention Mechanism can be applied to focus on the most important parts of the input sequence when making predictions.\n",
        "Attention helps the model weigh the significance of each event in the sequence, making it easier to determine their correct order.\n",
        "\n",
        "5. Output Layer: Sequence Prediction\n",
        "After processing the sequence with LSTM/GRU layers, the model generates an output that predicts the order of events.\n",
        "The output layer typically consists of dense layers with a softmax activation function, which outputs a probability distribution over the possible event orders.\n",
        "\n",
        "6. Decoding the Output\n",
        "Training: During training, the model is trained to minimize the difference between its predicted order and the correct order (ground truth). The correct order comes from the temporal relations (T-LINKs) in the dataset.\n",
        "Inference: During inference, the model outputs a sequence of indices that represent the predicted chronological order of the events.\n",
        "\n",
        "7. Example\n",
        "Consider a sequence of three events:\n",
        "\n",
        "Input Sequence: [\"Event A happened\", \"Event B happened\", \"Event C happened\"]\n",
        "\n",
        "Tokenized Input: [[1, 34, 56], [2, 34, 57], [3, 34, 58]] (where numbers are token indices)\n",
        "\n",
        "Model Prediction: The model processes this sequence and outputs [2, 1, 3], meaning the correct temporal order is Event B, Event A, Event C.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7lu0EDX394i"
      },
      "source": [
        "# 1.Extraction\n",
        "Whats going on here?\n",
        "\n",
        "1. Parsing TimeML Files\n",
        "\n",
        "2. Extracting Events and Context Sentences\n",
        "\n",
        "The events are stored in a list of dictionaries, where each dictionary contains:\n",
        "\n",
        "EVENT ID: The unique identifier for the event.\n",
        "\n",
        "EVENT Text: The text content of the event.\n",
        "\n",
        "Context Sentence: The sentence in which the event appears.\n",
        "\n",
        "3. Extracting Temporal Links (T-LINKs):\n",
        "\n",
        "The T-LINKs are stored in a list of dictionaries, where each dictionary contains:\n",
        "\n",
        "Event ID 1: The first event in the temporal relationship.\n",
        "\n",
        "Event ID 2: The second event in the temporal relationship.\n",
        "\n",
        "Relation: The type of temporal relation between the two events.\n",
        "\n",
        "\n",
        "4. Combining DataFrames\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Function to parse a TML file (TimeML format) and extract events, T-LINKs, and TIMEX3\n",
        "def parse_tml_with_context(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    events = []\n",
        "    tlinks = []\n",
        "    timex3s = []\n",
        "\n",
        "    # Extract events and TIMEX3\n",
        "    for s in root.iter('TEXT'):\n",
        "        sentence_text = s.text\n",
        "        for event in s.iter('EVENT'):\n",
        "            event_id = event.attrib['eid']\n",
        "            event_text = event.text\n",
        "            events.append({'EVENT ID': event_id, 'EVENT Text': event_text, 'Context Sentence': sentence_text})\n",
        "\n",
        "        for timex in s.iter('TIMEX3'):\n",
        "            timex_id = timex.attrib['tid']\n",
        "            timex_text = timex.text\n",
        "            timex3s.append({'TIMEX3 ID': timex_id, 'TIMEX3 Text': timex_text})\n",
        "\n",
        "    # Extract T-LINKs\n",
        "    for tlink in root.iter('TLINK'):\n",
        "        event_id_1 = tlink.attrib.get('eventInstanceID')\n",
        "        event_id_2 = tlink.attrib.get('relatedToEventInstance')\n",
        "        relation = tlink.attrib.get('relType')\n",
        "\n",
        "        if event_id_1 and event_id_2:\n",
        "            tlinks.append({'Event ID 1': event_id_1, 'Event ID 2': event_id_2, 'Relation': relation})\n",
        "\n",
        "    events_df = pd.DataFrame(events)\n",
        "    timex3_df = pd.DataFrame(timex3s)\n",
        "    tlinks_df = pd.DataFrame(tlinks)\n",
        "\n",
        "    return events_df, timex3_df, tlinks_df\n"
      ],
      "metadata": {
        "id": "G8Y99HGMP7BA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Parsing and Combining Datasets\n",
        "\n",
        "Function Definition: A function (parse_tml_with_context) is created to parse TimeML files and extract:\n",
        "\n",
        "Events: Including their IDs, text, and the context sentence they belong to.\n",
        "\n",
        "TIMEX3: Temporal expressions along with their IDs.\n",
        "\n",
        "T-LINKs: Relationships between events.\n",
        "\n",
        "Dataset Loading: The function is called for two datasets, TimeBank.tml and TimeEval3.tml, producing three DataFrames for each dataset (events, TIMEX3, T-LINKs).\n",
        "\n",
        "Combining DataFrames: The resulting DataFrames from both datasets are concatenated to form combined DataFrames for events, TIMEX3, and T-LINKs.\n",
        "\n",
        "Output: The first few rows of each combined DataFrame are printed for inspection."
      ],
      "metadata": {
        "id": "61CaffxPDbbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "timebank_events_df, timebank_timex3_df, timebank_tlinks_df = parse_tml_with_context('TimeBank.tml')\n",
        "timeeval3_events_df, timeeval3_timex3_df, timeeval3_tlinks_df = parse_tml_with_context('TimeEval3.tml')\n",
        "\n",
        "# Combine the datasets\n",
        "combined_events_df = pd.concat([timebank_events_df, timeeval3_events_df], ignore_index=True)\n",
        "combined_timex3_df = pd.concat([timebank_timex3_df, timeeval3_timex3_df], ignore_index=True)\n",
        "combined_tlinks_df = pd.concat([timebank_tlinks_df, timeeval3_tlinks_df], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "yzzHYX0vQAeS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Input Data"
      ],
      "metadata": {
        "id": "SrncZOFw8Cqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input Data Preparation\n",
        "\n",
        "\n",
        "Padded Sequences of Event Texts:\n",
        "\n",
        "This will be the primary input for the LSTM model.\n",
        "You will tokenize the text of events and pad the sequences to ensure uniform input length.\n",
        "\n",
        "Encoded Labels from T-LINKs:\n",
        "\n",
        "These will serve as the target output for the model.\n",
        "You will encode the relationships specified by the T-LINKs into numerical labels.\n",
        "\n",
        "TIMEX3 Information (Optional):\n",
        "\n",
        "If you choose to include TIMEX3 entities, this could provide additional temporal context.\n",
        "You can extract TIMEX3 texts and either use them as additional features or include them in the context of the event texts."
      ],
      "metadata": {
        "id": "42pYVQOb8qbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Prepare input data for events\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(combined_events_df['EVENT Text'].tolist())  # Fit on event texts\n",
        "event_sequences = tokenizer.texts_to_sequences(combined_events_df['EVENT Text'].tolist())  # Convert texts to sequences\n",
        "\n",
        "# Prepare input data for TIMEX3 (if present)\n",
        "timex3_sequences = tokenizer.texts_to_sequences(combined_timex3_df['TIMEX3 Text'].tolist())\n",
        "\n",
        "# Pad both event and TIMEX3 sequences\n",
        "max_length_events = max(len(s) for s in event_sequences)  # Max length for events\n",
        "max_length_timex3 = max(len(s) for s in timex3_sequences)  # Max length for TIMEX3\n",
        "\n",
        "# Pad sequences\n",
        "padded_event_sequences = pad_sequences(event_sequences, maxlen=max_length_events, padding='post')  # Pad event sequences\n",
        "padded_timex3_sequences = pad_sequences(timex3_sequences, maxlen=max_length_timex3, padding='post')  # Pad TIMEX3 sequences\n",
        "\n",
        "# Ensure both sequences have the same number of rows\n",
        "num_samples = max(padded_event_sequences.shape[0], padded_timex3_sequences.shape[0])\n",
        "\n",
        "# Adjust padding for events if needed\n",
        "if padded_event_sequences.shape[0] < num_samples:\n",
        "    extra_event_rows = np.zeros((num_samples - padded_event_sequences.shape[0], max_length_events))\n",
        "    padded_event_sequences = np.vstack([padded_event_sequences, extra_event_rows])\n",
        "\n",
        "# Adjust padding for TIMEX3 if needed\n",
        "if padded_timex3_sequences.shape[0] < num_samples:\n",
        "    extra_timex3_rows = np.zeros((num_samples - padded_timex3_sequences.shape[0], max_length_timex3))\n",
        "    padded_timex3_sequences = np.vstack([padded_timex3_sequences, extra_timex3_rows])\n",
        "\n",
        "# Combine event and TIMEX3 sequences\n",
        "combined_input_sequences = np.concatenate((padded_event_sequences, padded_timex3_sequences), axis=1)\n",
        "\n",
        "print(\"Shape of combined_input_sequences:\", combined_input_sequences.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE_avHaiQECG",
        "outputId": "53db10f2-c6aa-43bc-d71b-ebb0ea6626c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of combined_input_sequences: (56, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create encoded labels with a valid class for no relation\n",
        "relation_mapping = {relation: idx for idx, relation in enumerate(combined_tlinks_df['Relation'].unique())}\n",
        "encoded_labels = []\n",
        "for index, row in combined_events_df.iterrows():\n",
        "    # Find the corresponding relation for the event\n",
        "    relation = combined_tlinks_df[\n",
        "        (combined_tlinks_df['Event ID 1'] == row['EVENT ID']) |\n",
        "        (combined_tlinks_df['Event ID 2'] == row['EVENT ID'])\n",
        "    ]['Relation']\n",
        "\n",
        "    if not relation.empty:\n",
        "        encoded_labels.append(relation_mapping[relation.values[0]])\n",
        "    else:\n",
        "        # Assign a valid class index for \"no relation\"\n",
        "        encoded_labels.append(len(relation_mapping))  # Adjust if needed\n",
        "\n",
        "# Convert to a numpy array\n",
        "encoded_labels = np.array(encoded_labels)\n",
        "print(\"Encoded Labels Shape:\", encoded_labels.shape)\n",
        "print(\"Encoded Labels Unique Values:\", np.unique(encoded_labels))  # Check the unique values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMtJmP2iQ9_G",
        "outputId": "7d4e74ae-8019-4f62-fc8b-c81aebb38c01"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Labels Shape: (56,)\n",
            "Encoded Labels Unique Values: [6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(combined_input_sequences, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training Set Shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation Set Shape:\", X_val.shape, y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1US1zCkRASi",
        "outputId": "9ee0c657-04e0-4a13-9e2c-c49c49fa0981"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Shape: (44, 1) (44,)\n",
            "Validation Set Shape: (12, 1) (12,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Define model parameters\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Size of the vocabulary\n",
        "embedding_dim = 128  # Dimension of the embedding layer\n",
        "max_length = X_train.shape[1]  # Maximum length of the input sequences\n",
        "num_classes = len(relation_mapping) + 1  # Number of classes including \"no relation\"\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
        "\n",
        "# LSTM layer with L2 regularization\n",
        "model.add(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.5))  # Dropout for regularization\n",
        "\n",
        "# LSTM layer with L2 regularization\n",
        "model.add(LSTM(64, kernel_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Dense output layer with L2 regularization\n",
        "model.add(Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.001)))  # +1 for \"no relation\" class\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ-ZvBjoRGlk",
        "outputId": "a3e87477-7daa-415e-8752-3258ca6de3fa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 510ms/step - accuracy: 0.3722 - loss: 2.2279 - val_accuracy: 1.0000 - val_loss: 2.2099\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.2077 - val_accuracy: 1.0000 - val_loss: 2.1894\n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.1867 - val_accuracy: 1.0000 - val_loss: 2.1693\n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.1667 - val_accuracy: 1.0000 - val_loss: 2.1494\n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.1469 - val_accuracy: 1.0000 - val_loss: 2.1296\n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.1261 - val_accuracy: 1.0000 - val_loss: 2.1099\n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.1076 - val_accuracy: 1.0000 - val_loss: 2.0902\n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.0880 - val_accuracy: 1.0000 - val_loss: 2.0703\n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.0678 - val_accuracy: 1.0000 - val_loss: 2.0502\n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.0469 - val_accuracy: 1.0000 - val_loss: 2.0297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Loss: {loss}')\n",
        "print(f'Validation Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT2S8NhcROGC",
        "outputId": "3ab4cade-b3d3-4fd9-9d46-0d33929c6733"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.0297\n",
            "Validation Loss: 2.0296690464019775\n",
            "Validation Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input sentences\n",
        "example_events = [\n",
        "    \"John started his new job 1 month ago.\",\n",
        "    \"Mary graduated from university last week.\"\n",
        "]\n",
        "\n",
        "# Prepare input data for events\n",
        "event_sequences = tokenizer.texts_to_sequences(example_events)\n",
        "padded_event_sequences = pad_sequences(event_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Assuming we have TIMEX3 texts (adjust these as needed)\n",
        "example_timex3 = [\n",
        "    \"1 month ago\",\n",
        "    \"last week\"\n",
        "]\n",
        "\n",
        "# Prepare input data for TIMEX3\n",
        "timex3_sequences = tokenizer.texts_to_sequences(example_timex3)\n",
        "padded_timex3_sequences = pad_sequences(timex3_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Combine event and TIMEX3 sequences\n",
        "combined_input_sequences = np.concatenate((padded_event_sequences, padded_timex3_sequences), axis=1)\n"
      ],
      "metadata": {
        "id": "4JF-ZJhQR2Zz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(combined_input_sequences)\n",
        "\n",
        "# Get the indices of the events (or temporal relations)\n",
        "predicted_indices = np.argsort(np.argmax(predictions, axis=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ga8ZhViR7Fn",
        "outputId": "fd257c23-db72-4c71-a23b-4408ca79d0a9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predicted Event Indices (Temporal Order):\", predicted_indices)\n"
      ],
      "metadata": {
        "id": "LNDggxDBR95j",
        "outputId": "d238bbe4-f8dd-46be-e2ee-6879e5b452b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Event Indices (Temporal Order): [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Index 0 corresponds to the first event: \"John started his new job 1 month ago.\"\n",
        "Index 1 corresponds to the second event: \"Mary graduated from university last week.\"\n",
        "Interpretation:\n",
        "The model predicts that \"John started his new job 1 month ago\" happens before \"Mary graduated from university last week.\"\n",
        "This ordering makes sense based on the temporal information provided in the sentences:\n",
        "\"1 month ago\" suggests that the event occurred earlier than \"last week.\""
      ],
      "metadata": {
        "id": "5q1In1wTYHw9"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}