{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "# List of individual TimeBank files\n",
        "files = ['TimeBank1.tml', 'TimeBank2.tml', 'TimeBank3.tml', 'TimeBank4.tml']\n",
        "\n",
        "# Initialize lists to store the extracted data\n",
        "all_events = []\n",
        "all_timexes = []\n",
        "\n",
        "# Function to extract events and TIMEX3 from each .tml file\n",
        "def extract_from_tml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    events = []\n",
        "    timexes = []\n",
        "\n",
        "    for elem in root.iter():\n",
        "        if elem.tag == \"EVENT\":\n",
        "            event_class = elem.attrib.get(\"class\")\n",
        "            event_text = elem.text.strip() if elem.text else \"\"\n",
        "            events.append((event_class, event_text))\n",
        "\n",
        "        elif elem.tag == \"TIMEX3\":\n",
        "            time_type = elem.attrib.get(\"type\")\n",
        "            time_value = elem.attrib.get(\"value\")\n",
        "            timex_text = elem.text.strip() if elem.text else \"\"\n",
        "            timexes.append((time_type, time_value, timex_text))\n",
        "\n",
        "    return events, timexes\n",
        "\n",
        "# Loop through all TimeBank files and extract data from each\n",
        "for file in files:\n",
        "    events, timexes = extract_from_tml(file)\n",
        "    all_events.extend(events)\n",
        "    all_timexes.extend(timexes)\n",
        "\n",
        "# Convert the extracted data to DataFrames for easier exploration\n",
        "events_df = pd.DataFrame(all_events, columns=['EventClass', 'EventText'])\n",
        "timexes_df = pd.DataFrame(all_timexes, columns=['TimeType', 'TimeValue', 'TimexText'])\n",
        "\n",
        "# Preview the extracted data\n",
        "print(\"Events DataFrame:\\n\", events_df.head())\n",
        "print(\"Timexes DataFrame:\\n\", timexes_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIw6XXZgTcey",
        "outputId": "3e2ca56d-511d-4050-d519-65e003ec542f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Events DataFrame:\n",
            "    EventClass   EventText\n",
            "0  OCCURRENCE     turning\n",
            "1  OCCURRENCE  assistance\n",
            "2  OCCURRENCE     helping\n",
            "3  OCCURRENCE      fallen\n",
            "4  OCCURRENCE        lost\n",
            "Timexes DataFrame:\n",
            "    TimeType   TimeValue                   TimexText\n",
            "0      DATE  1998-01-08                    19980108\n",
            "1  DURATION         P1W                        week\n",
            "2  DURATION         P1D  the last twenty four hours\n",
            "3  DURATION         P5Y                   five year\n",
            "4  DURATION         P4Y                   four year\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Events DataFrame**\n",
        "\n",
        "\n",
        "EventClass: Type of event (e.g., \"OCCURRENCE\").\n",
        "\n",
        "EventText: Description of the event (e.g., \"turning\").\n",
        "\n",
        "\n",
        "**Timexes DataFrame**\n",
        "\n",
        "TimeType: Type of temporal expression (e.g., \"DATE\" or \"DURATION\").\n",
        "\n",
        "TimeValue: Standardized temporal representation (e.g., 1998-01-08 or P1W).\n",
        "\n",
        "TimexText: Text representation of the temporal expression (e.g., \"19980108\" or \"the last twenty-four hours\")."
      ],
      "metadata": {
        "id": "CTIzmSEOTg06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Combine EventText and TimexText for tokenization\n",
        "all_texts = events_df['EventText'].tolist() + timexes_df['TimexText'].tolist()\n",
        "\n",
        "# Initialize and fit the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_texts)\n",
        "\n",
        "# Convert EventText and TimexText to sequences\n",
        "event_sequences = tokenizer.texts_to_sequences(events_df['EventText'].tolist())\n",
        "timex_sequences = tokenizer.texts_to_sequences(timexes_df['TimexText'].tolist())\n",
        "\n",
        "# Set the maximum sequence length\n",
        "max_length = max(max(len(seq) for seq in event_sequences), max(len(seq) for seq in timex_sequences))\n",
        "\n",
        "# Pad sequences\n",
        "padded_event_sequences = pad_sequences(event_sequences, maxlen=max_length, padding='post')\n",
        "padded_timex_sequences = pad_sequences(timex_sequences, maxlen=max_length, padding='post')\n",
        "\n"
      ],
      "metadata": {
        "id": "yOjSczQNTvZx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "# Current date for comparison\n",
        "current_date = datetime.now()\n",
        "\n",
        "# Function to determine if an event has decayed\n",
        "def determine_validity(event_date):\n",
        "    if event_date:\n",
        "        # Check if event_date is in a date format (with optional time)\n",
        "        date_match = re.match(r'\\d{4}-\\d{2}-\\d{2}(T\\d{2}:\\d{2}:\\d{2})?', event_date)\n",
        "        if date_match:\n",
        "            event_datetime = datetime.fromisoformat(event_date)  # Handles both date and time\n",
        "            return 1 if (current_date - event_datetime).days <= 365 else 0\n",
        "\n",
        "        # Check if it's a duration (like P1W, P5Y)\n",
        "        duration_match = re.match(r'P(\\d+)([YMDW])', event_date)\n",
        "        if duration_match:\n",
        "            duration_value = int(duration_match.group(1))\n",
        "            duration_unit = duration_match.group(2)\n",
        "\n",
        "            # Define how to handle different duration units\n",
        "            if duration_unit == 'Y':  # Years\n",
        "                return 1  # Still valid\n",
        "            elif duration_unit == 'M':  # Months\n",
        "                return 1  # Still valid\n",
        "            elif duration_unit == 'D':  # Days\n",
        "                return 1 if duration_value <= 30 else 0  # Valid if less than 30 days\n",
        "            elif duration_unit == 'W':  # Weeks\n",
        "                return 1 if duration_value <= 4 else 0  # Valid if less than 4 weeks\n",
        "\n",
        "    return 0  # Default to invalid if no valid date or duration\n",
        "\n",
        "# Create labels for events based on the closest TIMEX\n",
        "def get_validity_labels(events_df, timexes_df):\n",
        "    labels = []\n",
        "    for event in events_df['EventText']:  # Assuming event text relates to the timex\n",
        "        # Here you may need to determine the relevant TIMEX for the event\n",
        "        # For simplicity, we will check the first TIMEX. Modify as needed.\n",
        "        # This assumes you have some mapping mechanism between events and TIMEXes\n",
        "        if not timexes_df.empty:\n",
        "            timex_value = timexes_df.iloc[0]['TimeValue']  # Example: using the first TIMEX\n",
        "            validity = determine_validity(timex_value)\n",
        "            labels.append(validity)\n",
        "        else:\n",
        "            labels.append(0)  # No valid TIMEX found\n",
        "    return labels\n",
        "\n",
        "# Assign labels to events\n",
        "events_df['Validity'] = get_validity_labels(events_df, timexes_df)\n",
        "\n",
        "# Check the lengths\n",
        "print(\"Events DataFrame Length:\", len(events_df))\n",
        "print(\"Labels Length:\", len(events_df['Validity']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX60Hfu8U-3C",
        "outputId": "27d22088-4581-447e-9792-52c26a8f92b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Events DataFrame Length: 184\n",
            "Labels Length: 184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Parameters\n",
        "vocab_size = len(tokenizer.word_index) + 1  # +1 for padding\n",
        "embedding_dim = 100\n",
        "max_length = padded_event_sequences.shape[1]\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5v5imsEeCy5",
        "outputId": "964ae1ab-37be-498a-8f99-f791a542fe2b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Example sentence\n",
        "new_sentence = \"The project was completed in June 2022, and the results were submitted for review.\"\n",
        "\n",
        "# Preprocess the sentence: Tokenize and pad\n",
        "sequence = tokenizer.texts_to_sequences([new_sentence])\n",
        "padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')\n",
        "\n",
        "# Predict validity using the trained model\n",
        "prediction = model.predict(padded_sequence)\n",
        "\n",
        "# Interpret the prediction\n",
        "validity = 'valid' if prediction[0][0] > 0.5 else 'decayed'\n",
        "\n",
        "# Output the result\n",
        "print(f\"The information is {validity}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NZiTeLieZw9",
        "outputId": "bf368ef7-35e7-4c15-bf67-9b05a57edc1c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "The information is decayed.\n"
          ]
        }
      ]
    }
  ]
}