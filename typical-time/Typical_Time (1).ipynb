{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**The model is an LSTM-based classifier that predicts whether a given event sentence represents a \"Typical Time\" (indicative of a time-related event) or \"Not Typical Time\" (indicating that it does not denote a time-related event).**\n",
        "\n",
        "\n",
        " **\"Typical Time\" sentences refer to specific time frames or regular occurrences, while non-\"Typical Time\" sentences do not convey specific temporal information.**"
      ],
      "metadata": {
        "id": "7HsL9Ak-Ego4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('mc-taco.tsv', sep='\\t')\n",
        "\n",
        "# Rename the columns appropriately\n",
        "df.columns = ['islam_part', 'question', 'answer', 'no', 'stationarity']  # Adjust if needed\n",
        "df = df.rename(columns={'islam_part': 'event_sentence', 'stationarity': 'event_type'})\n",
        "\n",
        "# Filter to keep only 'Typical Time' and 'Stationarity'\n",
        "df = df[df['event_type'].isin(['Typical Time', 'Stationarity'])]\n",
        "\n",
        "# Convert labels to binary (1 for Typical Time, 0 for Stationarity)\n",
        "df['label'] = df['event_type'].apply(lambda x: 1 if x == 'Typical Time' else 0)\n",
        "\n",
        "# Select only the relevant columns: event_sentence and label\n",
        "df = df[['event_sentence', 'label']]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = df['event_sentence'].values\n",
        "y = df['label'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Tokenize the inputs\n",
        "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=512)\n",
        "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=512)\n",
        "\n",
        "# Create a PyTorch Dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create Dataset objects\n",
        "train_dataset = TextDataset(train_encodings, y_train)\n",
        "test_dataset = TextDataset(test_encodings, y_test)\n",
        "\n",
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, 128)\n",
        "        self.lstm = nn.LSTM(128, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.dropout(x[:, -1, :])  # Use the last time step\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = len(tokenizer.vocab)  # Size of vocabulary\n",
        "hidden_dim = 64  # Number of hidden units in LSTM\n",
        "output_dim = 1  # Binary classification\n",
        "n_layers = 1  # Number of LSTM layers\n",
        "dropout = 0.5  # Dropout rate\n",
        "batch_size = 32  # Batch size\n",
        "num_epochs = 5  # Number of epochs\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Initialize the model\n",
        "model = LSTMModel(input_dim, hidden_dim, output_dim, n_layers, dropout)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()  # Use BCEWithLogitsLoss for binary classification\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch['input_ids'])\n",
        "        loss = criterion(outputs.squeeze(), batch['labels'].float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        outputs = model(batch['input_ids'])\n",
        "        predictions = (torch.sigmoid(outputs.squeeze()) > 0.5).int()  # Convert logits to binary predictions\n",
        "        correct += (predictions == batch['labels']).sum().item()\n",
        "        total += batch['labels'].size(0)\n",
        "\n",
        "print(f'Test Accuracy: {correct / total:.4f}')\n",
        "\n",
        "# Sample test sentences for predictions\n",
        "test_sentences = [\n",
        "    \"The event took place last week.\",\n",
        "    \"He will finish the project by next month.\",\n",
        "    \"This was a significant historical moment.\",\n",
        "    \"The meeting has been scheduled for tomorrow.\",\n",
        "    \"There are plans for a new building in the city.\",\n",
        "    \"The law was passed two years ago.\",\n",
        "    \"She graduated last year.\",\n",
        "    \"The concert will happen in July.\",\n",
        "    \"They expect the results to come out soon.\",\n",
        "    \"It was a breakthrough moment in science.\",\n",
        "    \"The project deadline is approaching quickly.\",\n",
        "    \"This method has been proven effective over time.\",\n",
        "    \"He has always been a leader in the community.\",\n",
        "    \"The report was due yesterday.\",\n",
        "    \"They launched the product last summer.\",\n",
        "    \"This technology has evolved rapidly.\",\n",
        "    \"The findings were published last month.\",\n",
        "    \"The contract was renewed last week.\",\n",
        "    \"There will be an exhibition next fall.\",\n",
        "    \"The movie came out last year.\",\n",
        "    \"The survey results will be released next week.\",\n",
        "    \"They announced the merger last December.\",\n",
        "    \"The team was formed last season.\",\n",
        "    \"She received the award last night.\",\n",
        "    \"The application is due in two days.\",\n",
        "    \"This research has been ongoing for several years.\",\n",
        "    \"The festival occurs every summer.\",\n",
        "    \"They will review the application by next week.\",\n",
        "    \"The bill was introduced in Congress last year.\",\n",
        "    \"The service will be available by next quarter.\",\n",
        "    \"The changes were implemented two weeks ago.\",\n",
        "    \"She will begin her new role next month.\",\n",
        "    \"The results were favorable this year.\",\n",
        "    \"He is expected to return in three weeks.\",\n",
        "    \"The meeting is scheduled for next Wednesday.\",\n",
        "    \"The product launch is set for early next year.\",\n",
        "    \"They will announce the decision shortly.\",\n",
        "    \"The workshop was held last Friday.\",\n",
        "    \"The upgrades will be completed by next month.\",\n",
        "    \"This system has been reliable for years.\",\n",
        "    \"He will continue to work on the project.\",\n",
        "    \"The review process will start soon.\",\n",
        "    \"The findings were significant at the time.\",\n",
        "    \"The policy change takes effect next year.\",\n",
        "    \"The negotiations are ongoing.\"\n",
        "]\n",
        "\n",
        "# Tokenize and encode the test sentences\n",
        "test_encodings = tokenizer(test_sentences, truncation=True, padding=True, max_length=512)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "test_dataset = TextDataset(test_encodings, [0] * len(test_sentences))  # Placeholder labels\n",
        "\n",
        "# Make predictions\n",
        "model.eval()\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in DataLoader(test_dataset, batch_size=8):\n",
        "        outputs = model(batch['input_ids'])\n",
        "        preds = (torch.sigmoid(outputs.squeeze()) > 0.5).int()  # Convert logits to binary predictions\n",
        "        predictions.extend(preds.numpy())\n",
        "\n",
        "# Print predictions\n",
        "for sentence, prediction in zip(test_sentences, predictions):\n",
        "    print(f'Sentence: \"{sentence}\" | Prediction: {\"Typical Time\" if prediction == 1 else \"Not Typical Time\"}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4s2kPwHDenq",
        "outputId": "50c05bb8-9878-4c47-a119-335dbbb632b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6062\n",
            "Epoch 2/5, Loss: 0.6175\n",
            "Epoch 3/5, Loss: 0.6586\n",
            "Epoch 4/5, Loss: 0.6227\n",
            "Epoch 5/5, Loss: 0.7222\n",
            "Test Accuracy: 0.7368\n",
            "Sentence: \"The event took place last week.\" | Prediction: Typical Time\n",
            "Sentence: \"He will finish the project by next month.\" | Prediction: Typical Time\n",
            "Sentence: \"This was a significant historical moment.\" | Prediction: Typical Time\n",
            "Sentence: \"The meeting has been scheduled for tomorrow.\" | Prediction: Typical Time\n",
            "Sentence: \"There are plans for a new building in the city.\" | Prediction: Not Typical Time\n",
            "Sentence: \"The law was passed two years ago.\" | Prediction: Typical Time\n",
            "Sentence: \"She graduated last year.\" | Prediction: Typical Time\n",
            "Sentence: \"The concert will happen in July.\" | Prediction: Typical Time\n",
            "Sentence: \"They expect the results to come out soon.\" | Prediction: Typical Time\n",
            "Sentence: \"It was a breakthrough moment in science.\" | Prediction: Typical Time\n",
            "Sentence: \"The project deadline is approaching quickly.\" | Prediction: Typical Time\n",
            "Sentence: \"This method has been proven effective over time.\" | Prediction: Typical Time\n",
            "Sentence: \"He has always been a leader in the community.\" | Prediction: Typical Time\n",
            "Sentence: \"The report was due yesterday.\" | Prediction: Typical Time\n",
            "Sentence: \"They launched the product last summer.\" | Prediction: Typical Time\n",
            "Sentence: \"This technology has evolved rapidly.\" | Prediction: Typical Time\n",
            "Sentence: \"The findings were published last month.\" | Prediction: Typical Time\n",
            "Sentence: \"The contract was renewed last week.\" | Prediction: Typical Time\n",
            "Sentence: \"There will be an exhibition next fall.\" | Prediction: Typical Time\n",
            "Sentence: \"The movie came out last year.\" | Prediction: Typical Time\n",
            "Sentence: \"The survey results will be released next week.\" | Prediction: Typical Time\n",
            "Sentence: \"They announced the merger last December.\" | Prediction: Typical Time\n",
            "Sentence: \"The team was formed last season.\" | Prediction: Typical Time\n",
            "Sentence: \"She received the award last night.\" | Prediction: Typical Time\n",
            "Sentence: \"The application is due in two days.\" | Prediction: Typical Time\n",
            "Sentence: \"This research has been ongoing for several years.\" | Prediction: Typical Time\n",
            "Sentence: \"The festival occurs every summer.\" | Prediction: Typical Time\n",
            "Sentence: \"They will review the application by next week.\" | Prediction: Typical Time\n",
            "Sentence: \"The bill was introduced in Congress last year.\" | Prediction: Typical Time\n",
            "Sentence: \"The service will be available by next quarter.\" | Prediction: Typical Time\n",
            "Sentence: \"The changes were implemented two weeks ago.\" | Prediction: Typical Time\n",
            "Sentence: \"She will begin her new role next month.\" | Prediction: Typical Time\n",
            "Sentence: \"The results were favorable this year.\" | Prediction: Typical Time\n",
            "Sentence: \"He is expected to return in three weeks.\" | Prediction: Typical Time\n",
            "Sentence: \"The meeting is scheduled for next Wednesday.\" | Prediction: Typical Time\n",
            "Sentence: \"The product launch is set for early next year.\" | Prediction: Typical Time\n",
            "Sentence: \"They will announce the decision shortly.\" | Prediction: Typical Time\n",
            "Sentence: \"The workshop was held last Friday.\" | Prediction: Typical Time\n",
            "Sentence: \"The upgrades will be completed by next month.\" | Prediction: Typical Time\n",
            "Sentence: \"This system has been reliable for years.\" | Prediction: Typical Time\n",
            "Sentence: \"He will continue to work on the project.\" | Prediction: Typical Time\n",
            "Sentence: \"The review process will start soon.\" | Prediction: Typical Time\n",
            "Sentence: \"The findings were significant at the time.\" | Prediction: Typical Time\n",
            "Sentence: \"The policy change takes effect next year.\" | Prediction: Typical Time\n",
            "Sentence: \"The negotiations are ongoing.\" | Prediction: Typical Time\n"
          ]
        }
      ]
    }
  ]
}