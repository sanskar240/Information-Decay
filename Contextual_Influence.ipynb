{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('MATRES.csv')\n",
        "\n",
        "# Select relevant columns\n",
        "data = data[['bodytext', 'after', 'before', 'verb']]\n",
        "\n",
        "# Drop any rows with NaN values in the relevant columns\n",
        "data = data.dropna(subset=['bodytext', 'after', 'before', 'verb'])\n",
        "\n",
        "# Define labels based on the 'after' and 'before' columns\n",
        "data['label'] = np.where(data['after'] == 'yes', 1, 0)  # Assuming 'yes' indicates a valid match\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['bodytext'].tolist() + data['verb'].tolist())\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "def preprocess_data(data):\n",
        "    context_sequences = tokenizer.texts_to_sequences(data['bodytext'])\n",
        "    padded_context = pad_sequences(context_sequences, padding='post')\n",
        "    return padded_context, data['label'].values\n",
        "\n",
        "# Preprocess the data\n",
        "padded_context, labels = preprocess_data(data)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_context, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set parameters\n",
        "embedding_dim = 100\n",
        "lstm_units = 64\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim))\n",
        "model.add(LSTM(lstm_units))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Function to predict validity\n",
        "def predict_validity(context, target):\n",
        "    # Preprocess input\n",
        "    context_seq = tokenizer.texts_to_sequences([context])\n",
        "    target_seq = tokenizer.texts_to_sequences([target])\n",
        "    padded_context = pad_sequences(context_seq, padding='post')\n",
        "\n",
        "    # Create input data for prediction\n",
        "    input_data = padded_context  # Only use context for prediction in this example\n",
        "\n",
        "    # Make a prediction\n",
        "    prediction = model.predict(input_data)\n",
        "    return 1 if prediction[0][0] > 0.5 else 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is8BSW0GQtzv",
        "outputId": "d6aa7ad4-7c3a-48c2-a782-2ebdeb762a76"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-9ff3e6eb9769>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['label'] = np.where(data['after'] == 'yes', 1, 0)  # Assuming 'yes' indicates a valid match\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - accuracy: 0.9666 - loss: 0.3219 - val_accuracy: 1.0000 - val_loss: 8.6249e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 2.5489e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 5.1793e-04 - val_accuracy: 1.0000 - val_loss: 1.7609e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 4.3179e-04 - val_accuracy: 1.0000 - val_loss: 1.3280e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 2.9979e-04 - val_accuracy: 1.0000 - val_loss: 1.0694e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 2.4898e-04 - val_accuracy: 1.0000 - val_loss: 8.9396e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 2.0304e-04 - val_accuracy: 1.0000 - val_loss: 7.7610e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 1.8698e-04 - val_accuracy: 1.0000 - val_loss: 6.8347e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 1.7891e-04 - val_accuracy: 1.0000 - val_loss: 6.0464e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 1.7241e-04 - val_accuracy: 1.0000 - val_loss: 5.3689e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "context_example = \"The meeting was rescheduled to next week.\"\n",
        "target_example = \"The event will take place on Friday.\"\n",
        "validity = predict_validity(context_example, target_example)\n",
        "print(f\"Context: '{context_example}'\")\n",
        "print(f\"Target: '{target_example}'\")\n",
        "print(f\"Predicted validity (1: valid, 0: invalid): {validity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjGKhKZDQ4ii",
        "outputId": "722b7490-0b8b-4c2e-bcd5-cf2fd0063818"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "Context: 'The meeting was rescheduled to next week.'\n",
            "Target: 'The event will take place on Friday.'\n",
            "Predicted validity (1: valid, 0: invalid): 0\n"
          ]
        }
      ]
    }
  ]
}