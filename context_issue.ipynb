{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, Attention\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import spacy\n",
        "\n",
        "# Load spaCy's English model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Function to parse a TML file (TimeML format) and extract events, T-LINKs, and TIMEX3\n",
        "def parse_tml_with_context(file_path):\n",
        "    events = []\n",
        "    t_links = []\n",
        "    timex3 = []\n",
        "\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    for event in root.findall('.//EVENT'):\n",
        "        event_id = event.attrib.get('eid', 'N/A')  # Get event ID, default to 'N/A' if not found\n",
        "        text_element = event.find('TEXT')\n",
        "        if text_element is not None:  # Check if TEXT element exists\n",
        "            event_text = text_element.text.strip()\n",
        "            events.append((event_id, event_text))\n",
        "        else:\n",
        "            print(f\"Warning: No TEXT element found for event ID {event_id}.\")  # Debug info\n",
        "\n",
        "    for link in root.findall('.//T_LINK'):\n",
        "        t_links.append(link.attrib)\n",
        "\n",
        "    for timex in root.findall('.//TIMEX3'):\n",
        "        timex3.append(timex.attrib)\n",
        "\n",
        "    return events, t_links, timex3\n",
        "\n",
        "\n",
        "# Load the datasets\n",
        "timebank_events, _, _ = parse_tml_with_context('TimeBank.tml')\n",
        "timeeval3_events, _, _ = parse_tml_with_context('TimeEval3.tml')\n",
        "\n",
        "# Sample dataset preparation (using events from TimeBank for demonstration)\n",
        "sample_data = [event[1] for event in timebank_events]  # Extracting event texts\n",
        "\n",
        "# Prepare input data for events\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sample_data)\n",
        "\n",
        "# Define model parameters\n",
        "max_length = 50  # Define max sequence length\n",
        "embedding_dim = 128  # Define embedding dimensions\n",
        "lstm_units = 64  # Define LSTM units\n",
        "\n",
        "# Build the LSTM model with Attention Mechanism\n",
        "def build_model(vocab_size, embedding_dim, max_length, lstm_units):\n",
        "    input_layer = Input(shape=(max_length,))\n",
        "    embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length)(input_layer)\n",
        "    lstm_layer = Bidirectional(LSTM(lstm_units, return_sequences=True))(embedding_layer)\n",
        "    attention_layer = Attention()([lstm_layer, lstm_layer])  # Attention mechanism\n",
        "    flatten_layer = Dropout(0.5)(attention_layer)\n",
        "    output_layer = Dense(1, activation='sigmoid')(flatten_layer)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Build and summarize the model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "attention_model = build_model(vocab_size, embedding_dim, max_length, lstm_units)\n",
        "attention_model.summary()\n",
        "\n",
        "# Function to extract events using spaCy's POS tagging (verbs as events)\n",
        "def extract_events_with_spacy(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    events = []\n",
        "\n",
        "    for token in doc:\n",
        "        # Detect events with verbs\n",
        "        if token.pos_ == 'VERB':\n",
        "            events.append(token.text)\n",
        "\n",
        "    return events\n",
        "\n",
        "# Function to prepare event sequences for a given sentence\n",
        "def prepare_event_sequences(events, tokenizer, maxlen):\n",
        "    event_sequences = tokenizer.texts_to_sequences(events)  # Convert events to sequences\n",
        "    padded_sequences = pad_sequences(event_sequences, padding='post', maxlen=maxlen)  # Pad sequences\n",
        "    return padded_sequences\n",
        "\n",
        "# Function to order events based on model predictions\n",
        "def predict_event_order(sentence, model, tokenizer, maxlen):\n",
        "    events = extract_events_with_spacy(sentence)\n",
        "\n",
        "    if not events:\n",
        "        return \"No events detected in the sentence.\"\n",
        "\n",
        "    event_sequences = prepare_event_sequences(events, tokenizer, maxlen)\n",
        "    predictions = model.predict(event_sequences)  # Get predictions for each event\n",
        "\n",
        "    # Get predicted classes (indices of the highest predicted score)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Sort the events based on their predicted class scores\n",
        "    sorted_events = sorted(zip(predicted_classes, events), key=lambda x: x[0])\n",
        "\n",
        "    # Return the ordered events\n",
        "    ordered_events = [event for _, event in sorted_events]\n",
        "    return ordered_events\n",
        "\n",
        "# Define a complex sample sentence with interrelated events\n",
        "complex_sample_sentence = (\n",
        "    \"After Alice woke up, she decided to prepare breakfast. \"\n",
        "    \"While the eggs were frying, her friend Bob arrived unexpectedly. \"\n",
        "    \"They chatted for a while, and then they both went for a jog in the park before it started to rain.\"\n",
        ")\n",
        "\n",
        "# Predict event order\n",
        "ordered_events_complex = predict_event_order(complex_sample_sentence, attention_model, tokenizer, max_length)\n",
        "print(\"Predicted Order of Events:\", ordered_events_complex)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_zsYxbOKK7gG",
        "outputId": "56af58d2-9f05-4303-b864-6e92ed04d7be"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No TEXT element found for event ID e1.\n",
            "Warning: No TEXT element found for event ID e2.\n",
            "Warning: No TEXT element found for event ID e4.\n",
            "Warning: No TEXT element found for event ID e6.\n",
            "Warning: No TEXT element found for event ID e7.\n",
            "Warning: No TEXT element found for event ID e9.\n",
            "Warning: No TEXT element found for event ID e49.\n",
            "Warning: No TEXT element found for event ID e10.\n",
            "Warning: No TEXT element found for event ID e11.\n",
            "Warning: No TEXT element found for event ID e12.\n",
            "Warning: No TEXT element found for event ID e13.\n",
            "Warning: No TEXT element found for event ID e14.\n",
            "Warning: No TEXT element found for event ID e15.\n",
            "Warning: No TEXT element found for event ID e17.\n",
            "Warning: No TEXT element found for event ID e18.\n",
            "Warning: No TEXT element found for event ID e19.\n",
            "Warning: No TEXT element found for event ID e20.\n",
            "Warning: No TEXT element found for event ID e50.\n",
            "Warning: No TEXT element found for event ID e21.\n",
            "Warning: No TEXT element found for event ID e22.\n",
            "Warning: No TEXT element found for event ID e51.\n",
            "Warning: No TEXT element found for event ID e25.\n",
            "Warning: No TEXT element found for event ID e26.\n",
            "Warning: No TEXT element found for event ID e27.\n",
            "Warning: No TEXT element found for event ID e29.\n",
            "Warning: No TEXT element found for event ID e30.\n",
            "Warning: No TEXT element found for event ID e34.\n",
            "Warning: No TEXT element found for event ID e35.\n",
            "Warning: No TEXT element found for event ID e36.\n",
            "Warning: No TEXT element found for event ID e39.\n",
            "Warning: No TEXT element found for event ID e40.\n",
            "Warning: No TEXT element found for event ID e1.\n",
            "Warning: No TEXT element found for event ID e2.\n",
            "Warning: No TEXT element found for event ID e3.\n",
            "Warning: No TEXT element found for event ID e4.\n",
            "Warning: No TEXT element found for event ID e6.\n",
            "Warning: No TEXT element found for event ID e7.\n",
            "Warning: No TEXT element found for event ID e8.\n",
            "Warning: No TEXT element found for event ID e9.\n",
            "Warning: No TEXT element found for event ID e10.\n",
            "Warning: No TEXT element found for event ID e12.\n",
            "Warning: No TEXT element found for event ID e13.\n",
            "Warning: No TEXT element found for event ID e14.\n",
            "Warning: No TEXT element found for event ID e16.\n",
            "Warning: No TEXT element found for event ID e19.\n",
            "Warning: No TEXT element found for event ID e21.\n",
            "Warning: No TEXT element found for event ID e22.\n",
            "Warning: No TEXT element found for event ID e23.\n",
            "Warning: No TEXT element found for event ID e24.\n",
            "Warning: No TEXT element found for event ID e25.\n",
            "Warning: No TEXT element found for event ID e26.\n",
            "Warning: No TEXT element found for event ID e27.\n",
            "Warning: No TEXT element found for event ID e28.\n",
            "Warning: No TEXT element found for event ID e29.\n",
            "Warning: No TEXT element found for event ID e30.\n",
            "Warning: No TEXT element found for event ID e31.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │            \u001b[38;5;34m128\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m98,816\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention_6 (\u001b[38;5;33mAttention\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ bidirectional_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ bidirectional_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ attention_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │            \u001b[38;5;34m129\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ bidirectional_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,073\u001b[0m (387.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,073</span> (387.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m99,073\u001b[0m (387.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,073</span> (387.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n",
            "Predicted Order of Events: ['woke', 'decided', 'prepare', 'frying', 'arrived', 'chatted', 'went', 'started', 'rain']\n"
          ]
        }
      ]
    }
  ]
}