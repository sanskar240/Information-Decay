{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Temporal Ordering in PyTorch\n"
      ],
      "metadata": {
        "id": "TmMKE0AtzDxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Function to parse a TML file (TimeML format) and extract events, T-LINKs, and TIMEX3\n",
        "def parse_tml_with_context(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    events = []\n",
        "    tlinks = []\n",
        "    timex3s = []\n",
        "\n",
        "    for s in root.iter('TEXT'):\n",
        "        sentence_text = s.text\n",
        "        for event in s.iter('EVENT'):\n",
        "            event_id = event.attrib['eid']\n",
        "            event_text = event.text\n",
        "            events.append({'EVENT ID': event_id, 'EVENT Text': event_text, 'Context Sentence': sentence_text})\n",
        "\n",
        "        for timex in s.iter('TIMEX3'):\n",
        "            timex_id = timex.attrib['tid']\n",
        "            timex_text = timex.text\n",
        "            timex3s.append({'TIMEX3 ID': timex_id, 'TIMEX3 Text': timex_text})\n",
        "\n",
        "    for tlink in root.iter('TLINK'):\n",
        "        event_id_1 = tlink.attrib.get('eventInstanceID')\n",
        "        event_id_2 = tlink.attrib.get('relatedToEventInstance')\n",
        "        relation = tlink.attrib.get('relType')\n",
        "\n",
        "        if event_id_1 and event_id_2:\n",
        "            tlinks.append({'Event ID 1': event_id_1, 'Event ID 2': event_id_2, 'Relation': relation})\n",
        "\n",
        "    events_df = pd.DataFrame(events)\n",
        "    timex3_df = pd.DataFrame(timex3s)\n",
        "    tlinks_df = pd.DataFrame(tlinks)\n",
        "\n",
        "    return events_df, timex3_df, tlinks_df\n",
        "\n",
        "# Load datasets\n",
        "timebank_events_df, timebank_timex3_df, timebank_tlinks_df = parse_tml_with_context('TimeBank.tml')\n",
        "timeeval3_events_df, timeeval3_timex3_df, timeeval3_tlinks_df = parse_tml_with_context('TimeEval3.tml')\n",
        "\n",
        "# Combine datasets\n",
        "combined_events_df = pd.concat([timebank_events_df, timeeval3_events_df], ignore_index=True)\n",
        "combined_timex3_df = pd.concat([timebank_timex3_df, timeeval3_timex3_df], ignore_index=True)\n",
        "combined_tlinks_df = pd.concat([timebank_tlinks_df, timeeval3_tlinks_df], ignore_index=True)\n",
        "\n",
        "# Prepare input data for events\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(combined_events_df['EVENT Text'].tolist())\n",
        "event_sequences = tokenizer.texts_to_sequences(combined_events_df['EVENT Text'].tolist())\n",
        "padded_event_sequences = pad_sequences(event_sequences, padding='post', dtype='int32')\n",
        "\n",
        "# Label encoding for relations\n",
        "relation_mapping = {relation: idx for idx, relation in enumerate(combined_tlinks_df['Relation'].unique())}\n",
        "encoded_labels = []\n",
        "for index, row in combined_events_df.iterrows():\n",
        "    relation = combined_tlinks_df[\n",
        "        (combined_tlinks_df['Event ID 1'] == row['EVENT ID']) |\n",
        "        (combined_tlinks_df['Event ID 2'] == row['EVENT ID'])\n",
        "    ]['Relation']\n",
        "\n",
        "    if not relation.empty:\n",
        "        encoded_labels.append(relation_mapping[relation.values[0]])\n",
        "    else:\n",
        "        encoded_labels.append(len(relation_mapping))  # For \"no relation\"\n",
        "\n",
        "encoded_labels = np.array(encoded_labels)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(padded_event_sequences, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.long)\n",
        "X_val = torch.tensor(X_val, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_val = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader for batching\n",
        "batch_size = 32\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "val_data = TensorDataset(X_val, y_val)\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "\n",
        "# Define the PyTorch LSTM model\n",
        "class EventOrderingModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.5):\n",
        "        super(EventOrderingModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, dropout=dropout, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        lstm_out = lstm_out[:, -1, :]  # Take the output of the last time step\n",
        "        output = self.fc(self.dropout(lstm_out))\n",
        "        return output\n",
        "\n",
        "# Model parameters\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 128\n",
        "hidden_dim = 64\n",
        "output_dim = len(relation_mapping) + 1  # Include \"no relation\" class\n",
        "\n",
        "# Instantiate the model\n",
        "model = EventOrderingModel(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {running_loss/len(train_loader)}, Accuracy: {train_accuracy}')\n",
        "\n",
        "# Evaluation on validation set\n",
        "model.eval()\n",
        "val_loss = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "val_accuracy = 100 * correct / total\n",
        "print(f'Validation Loss: {val_loss/len(val_loader)}, Validation Accuracy: {val_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf55Vwa7zjXE",
        "outputId": "a588ad28-9aaa-4934-d007-8cbd0101aeef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.8906916379928589, Accuracy: 36.36363636363637\n",
            "Epoch 2/10, Loss: 1.8768877983093262, Accuracy: 45.45454545454545\n",
            "Epoch 3/10, Loss: 1.8572030067443848, Accuracy: 61.36363636363637\n",
            "Epoch 4/10, Loss: 1.833652913570404, Accuracy: 84.0909090909091\n",
            "Epoch 5/10, Loss: 1.807333528995514, Accuracy: 97.72727272727273\n",
            "Epoch 6/10, Loss: 1.7889308333396912, Accuracy: 95.45454545454545\n",
            "Epoch 7/10, Loss: 1.7780386805534363, Accuracy: 95.45454545454545\n",
            "Epoch 8/10, Loss: 1.746815800666809, Accuracy: 97.72727272727273\n",
            "Epoch 9/10, Loss: 1.735805630683899, Accuracy: 100.0\n",
            "Epoch 10/10, Loss: 1.70173841714859, Accuracy: 100.0\n",
            "Validation Loss: 1.676618218421936, Validation Accuracy: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Define the LSTM-based PyTorch model\n",
        "class EventOrderingModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, lstm_units, num_classes):\n",
        "        super(EventOrderingModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, lstm_units, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(lstm_units * 2, 1)  # Output will be a single number for temporal ordering\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        out = self.fc(lstm_out[:, -1, :])  # Take the last output for ordering\n",
        "        return out\n",
        "\n",
        "# Define model parameters\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size\n",
        "embedding_dim = 128  # Embedding dimension\n",
        "lstm_units = 64  # LSTM units\n",
        "\n",
        "# Instantiate the model\n",
        "model = EventOrderingModel(vocab_size, embedding_dim, lstm_units, 1)\n",
        "\n",
        "# Load the trained model weights if available\n",
        "# model.load_state_dict(torch.load('path_to_saved_model.pth'))\n",
        "\n",
        "# Switch the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Example sentences with non-linear, non-chronological events (compound sentences)\n",
        "example_sentences = [\n",
        "    \"Alice made breakfast, woke up, attended a meeting, and then went for a run.\",\n",
        "    \"John returned home, went to the store, and bought milk.\",\n",
        "    \"She found the gift, received the package, and opened it.\",\n",
        "    \"Tom went to sleep, cleaned the house, and fed the cat.\"\n",
        "]\n",
        "\n",
        "# Corresponding events (for demonstration)\n",
        "example_events = [\n",
        "    [\"made breakfast\", \"woke up\", \"attended a meeting\", \"went for a run\"],\n",
        "    [\"returned home\", \"went to the store\", \"bought milk\"],\n",
        "    [\"found the gift\", \"received the package\", \"opened it\"],\n",
        "    [\"went to sleep\", \"cleaned the house\", \"fed the cat\"]\n",
        "]\n",
        "\n",
        "# Tokenize and pad the example events\n",
        "for events in example_events:\n",
        "    example_event_sequences = tokenizer.texts_to_sequences(events)\n",
        "    padded_event_sequences = pad_sequences(example_event_sequences, padding='post', maxlen=X_train.shape[1])\n",
        "\n",
        "    # Convert padded sequences to torch tensors\n",
        "    input_tensor = torch.tensor(padded_event_sequences, dtype=torch.long)\n",
        "\n",
        "    # Make predictions using the trained model\n",
        "    with torch.no_grad():\n",
        "        predictions = model(input_tensor)\n",
        "\n",
        "    # Predictions represent the temporal order\n",
        "    event_order = predictions.squeeze().numpy()\n",
        "\n",
        "    # Zip the event texts with their predicted order\n",
        "    events_with_order = list(zip(events, event_order))\n",
        "\n",
        "    # Sort events based on their predicted temporal order\n",
        "    sorted_events = sorted(events_with_order, key=lambda x: x[1])\n",
        "\n",
        "    # Display only the events in the predicted correct order\n",
        "    print(\"\\nSentence:\", example_sentences[example_events.index(events)])\n",
        "    print(\"Events in predicted temporal order:\")\n",
        "    for event, _ in sorted_events:\n",
        "        print(f\"Event: '{event}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5skrEz6c1Rjl",
        "outputId": "6e7cefd1-5536-4851-eaca-5a5d26b58123"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: Alice made breakfast, woke up, attended a meeting, and then went for a run.\n",
            "Events in predicted temporal order:\n",
            "Event: 'made breakfast'\n",
            "Event: 'woke up'\n",
            "Event: 'attended a meeting'\n",
            "Event: 'went for a run'\n",
            "\n",
            "Sentence: John returned home, went to the store, and bought milk.\n",
            "Events in predicted temporal order:\n",
            "Event: 'returned home'\n",
            "Event: 'went to the store'\n",
            "Event: 'bought milk'\n",
            "\n",
            "Sentence: She found the gift, received the package, and opened it.\n",
            "Events in predicted temporal order:\n",
            "Event: 'found the gift'\n",
            "Event: 'received the package'\n",
            "Event: 'opened it'\n",
            "\n",
            "Sentence: Tom went to sleep, cleaned the house, and fed the cat.\n",
            "Events in predicted temporal order:\n",
            "Event: 'went to sleep'\n",
            "Event: 'cleaned the house'\n",
            "Event: 'fed the cat'\n"
          ]
        }
      ]
    }
  ]
}